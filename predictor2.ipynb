{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOj8jitIhQv35VCZmuQysS2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PierreBond/SP_PREDICTOR/blob/main/predictor2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXHcb-9S1hCf",
        "outputId": "3bae6109-34dd-4e12-f7e0-49b7ee132ac5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.12/dist-packages (0.2.66)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.5.1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.4.7)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.12/dist-packages (from yfinance) (3.18.3)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.13.5)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.13.0)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2025.11.12)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.23)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install numpy pandas matplotlib scikit-learn tensorflow yfinance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, LayerNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "jtMK9DnG2XBh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StockPredictor:\n",
        "    def __init__(self, ticker, seq_length=60, epochs=50):\n",
        "        if not isinstance(ticker, str) or len(ticker) == 0:\n",
        "            raise ValueError(\"Ticker must be a non-empty string\")\n",
        "        self.ticker = ticker\n",
        "        self.seq_length = seq_length\n",
        "        self.epochs = epochs\n",
        "        self.scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        self.model = None\n",
        "        self.data = None\n",
        "        self.X_test = None\n",
        "        self.y_test = None\n",
        "        self.split_idx = None\n",
        "        self.test_data = None\n",
        "        self.close_scaler = None\n",
        "\n",
        "    def fetch_data(self, start='2010-01-01', end='2023-12-31'):\n",
        "        \"\"\"Fetch OHLCV data with error handling.\"\"\"\n",
        "        try:\n",
        "            self.data = yf.download(self.ticker, start=start, end=end)\n",
        "            if self.data.empty:\n",
        "                raise ValueError(f\"No data found for ticker: {self.ticker}\")\n",
        "            self.data['Returns'] = self.data['Close'].pct_change()\n",
        "            self.data['RSI'] = self._compute_rsi(self.data['Close'], window=14)\n",
        "            self.data['MACD'] = self.data['Close'].ewm(span=12).mean() - self.data['Close'].ewm(span=26).mean()\n",
        "            self.data.dropna(inplace=True)\n",
        "            return self.data\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching data: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _compute_rsi(self, series, window=14):\n",
        "        delta = series.diff()\n",
        "        gain = (delta.where(delta > 0, 0)).rolling(window).mean()\n",
        "        loss = (-delta.where(delta < 0, 0)).rolling(window).mean()\n",
        "        return 100 - (100 / (1 + gain / loss))\n",
        "\n",
        "    def preprocess_data(self):\n",
        "        \"\"\"Split before scaling to prevent leakage.\"\"\"\n",
        "        # Start with simpler features for better generalization\n",
        "        features = self.data[['Close', 'Volume', 'RSI']].values  # Simplified feature set\n",
        "\n",
        "        self.split_idx = int(0.8 * len(features))\n",
        "        train_features, test_features = features[:self.split_idx], features[self.split_idx:]\n",
        "\n",
        "        train_scaled = self.scaler.fit_transform(train_features)\n",
        "        test_scaled = self.scaler.transform(test_features)\n",
        "\n",
        "        X_train, y_train = self._create_sequences(train_scaled)\n",
        "        X_test, y_test = self._create_sequences(test_scaled)\n",
        "\n",
        "        self.X_test, self.y_test = X_test, y_test\n",
        "        self.test_data = self.data.iloc[self.split_idx + self.seq_length:]\n",
        "        self.close_scaler = MinMaxScaler()  # Separate scaler for inverse transform\n",
        "        self.close_scaler.fit(features[:, 0].reshape(-1, 1))\n",
        "\n",
        "        return X_train, X_test, y_train, y_test\n",
        "\n",
        "    def _create_sequences(self, data):\n",
        "        X, y = [], []\n",
        "        for i in range(len(data) - self.seq_length):\n",
        "            X.append(data[i:i+self.seq_length])\n",
        "            y.append(data[i+self.seq_length, 0])\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    def create_simpler_model(self):\n",
        "        \"\"\"Simplified LSTM model without attention for better generalization.\"\"\"\n",
        "        inputs = Input(shape=(self.seq_length, 3))  # 3 features: Close, Volume, RSI\n",
        "\n",
        "        # Simplified architecture with regularization\n",
        "        x = LSTM(32, return_sequences=True, dropout=0.3)(inputs)\n",
        "        x = LayerNormalization()(x)\n",
        "        x = LSTM(16, dropout=0.3)(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "\n",
        "        outputs = Dense(1)(x)\n",
        "\n",
        "        model = Model(inputs, outputs)\n",
        "        model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "            loss='huber',\n",
        "            metrics=['mae']\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def train(self):\n",
        "        X_train, X_test, y_train, y_test = self.preprocess_data()\n",
        "        self.model = self.create_simpler_model()\n",
        "\n",
        "        callbacks = [\n",
        "            EarlyStopping(patience=15, restore_best_weights=True, monitor='val_loss', min_delta=0.001),\n",
        "            ReduceLROnPlateau(factor=0.5, patience=7, min_lr=1e-7, monitor='val_loss', verbose=1)\n",
        "        ]\n",
        "\n",
        "        history = self.model.fit(\n",
        "            X_train, y_train,\n",
        "            epochs=self.epochs,\n",
        "            batch_size=32,\n",
        "            validation_data=(X_test, y_test),\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "        return history\n",
        "\n",
        "    def predict_with_uncertainty(self, n_samples=10):\n",
        "        \"\"\"Monte Carlo dropout for uncertainty estimation.\"\"\"\n",
        "        mc_predictions = np.stack([self.model.predict(self.X_test) for _ in range(n_samples)])\n",
        "        mean = mc_predictions.mean(axis=0)\n",
        "\n",
        "        # Inverse transform only the close price\n",
        "        dummy = np.zeros((len(mean), 3))\n",
        "        dummy[:, 0] = mean.flatten()\n",
        "        predictions = self.close_scaler.inverse_transform(dummy)[:, 0]\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def backtest(self, predictions, threshold=0.001):  # Reduced threshold\n",
        "        \"\"\"Robust backtesting with proper data alignment.\"\"\"\n",
        "        test_prices = self.test_data['Close'].values\n",
        "\n",
        "        min_len = min(len(predictions), len(test_prices))\n",
        "        predictions = predictions[:min_len]\n",
        "        test_prices = test_prices[:min_len]\n",
        "\n",
        "        # More conservative signal generation\n",
        "        signals = np.where(predictions[:-1] > test_prices[:-1] * (1 + threshold), 1, -1)\n",
        "        returns = test_prices[1:] / test_prices[:-1] - 1\n",
        "        strategy_returns = signals * returns - 0.001  # Transaction cost\n",
        "\n",
        "        # Calculate metrics\n",
        "        sharpe = np.sqrt(252) * strategy_returns.mean() / strategy_returns.std()\n",
        "        max_drawdown = (np.maximum.accumulate(1 + strategy_returns) - (1 + strategy_returns)).max()\n",
        "        total_return = np.prod(1 + strategy_returns) - 1\n",
        "        annual_return = (1 + total_return) ** (252 / len(strategy_returns)) - 1\n",
        "\n",
        "        return sharpe, max_drawdown, total_return, annual_return\n",
        "\n",
        "    def plot_results(self):\n",
        "        \"\"\"Plot with properly aligned data and uncertainty bands.\"\"\"\n",
        "        if self.test_data is None:\n",
        "            raise ValueError(\"Test data not available. Run preprocess_data() first.\")\n",
        "\n",
        "        pred_mean = self.predict_with_uncertainty()\n",
        "\n",
        "        plt.figure(figsize=(14, 8))\n",
        "\n",
        "        # Price plot\n",
        "        plt.subplot(2, 1, 1)\n",
        "        plt.plot(self.test_data.index, self.test_data['Close'].values,\n",
        "                label='True Price', linewidth=2)\n",
        "        plt.plot(self.test_data.index, pred_mean, label='Predicted', alpha=0.8)\n",
        "        plt.title(f\"{self.ticker} Stock Price Prediction\")\n",
        "        plt.ylabel(\"Price ($)\")\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        # Returns distribution\n",
        "        plt.subplot(2, 1, 2)\n",
        "        test_returns = self.test_data['Returns'].values\n",
        "        plt.hist(test_returns, bins=50, alpha=0.7, edgecolor='black', color='skyblue')\n",
        "        plt.axvline(np.mean(test_returns), color='red', linestyle='--',\n",
        "                   label=f'Mean: {np.mean(test_returns):.2%}')\n",
        "        plt.title(\"Returns Distribution\")\n",
        "        plt.ylabel(\"Frequency\")\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def evaluate_diagnostics(self):\n",
        "        \"\"\"Additional diagnostics to understand model performance.\"\"\"\n",
        "        pred_mean = self.predict_with_uncertainty()\n",
        "\n",
        "        # Check alignment\n",
        "        print(f\"Prediction length: {len(pred_mean)}\")\n",
        "        print(f\"Test prices length: {len(self.test_data['Close'])}\")\n",
        "\n",
        "        # Directional accuracy\n",
        "        actual_next = self.test_data['Close'].values[1:]\n",
        "        pred_next = pred_mean[:-1]\n",
        "        direction_correct = np.mean((actual_next > self.test_data['Close'].values[:-1]) ==\n",
        "                                 (pred_next > self.test_data['Close'].values[:-1]))\n",
        "        print(f\"Directional accuracy: {direction_correct:.2%}\")\n",
        "\n",
        "        # Basic error metrics\n",
        "        rmse = np.sqrt(mean_squared_error(self.test_data['Close'].values[1:], pred_next))\n",
        "        print(f\"RMSE: ${rmse:.2f}\")\n",
        "\n",
        "        return direction_correct, rmse\n",
        ""
      ],
      "metadata": {
        "id": "NSqIRvF312hY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "        # Initialize and train\n",
        "        predictor = StockPredictor(\"AAPL\", seq_length=60, epochs=50)\n",
        "        predictor.fetch_data()\n",
        "        predictor.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGN_263v2FrO",
        "outputId": "686ef6fd-150c-4caf-c8d0-55a4e2592ce4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3092242290.py:20: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  self.data = yf.download(self.ticker, start=start, end=end)\n",
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - loss: 0.0830 - mae: 0.3097 - val_loss: 0.4358 - val_mae: 0.9241 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 0.0514 - mae: 0.2496 - val_loss: 0.3254 - val_mae: 0.7954 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0480 - mae: 0.2316 - val_loss: 0.2754 - val_mae: 0.7301 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0366 - mae: 0.2035 - val_loss: 0.2464 - val_mae: 0.6897 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - loss: 0.0288 - mae: 0.1819 - val_loss: 0.2234 - val_mae: 0.6560 - learning_rate: 1.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0287 - mae: 0.1759 - val_loss: 0.2143 - val_mae: 0.6423 - learning_rate: 1.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - loss: 0.0257 - mae: 0.1670 - val_loss: 0.2029 - val_mae: 0.6246 - learning_rate: 1.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - loss: 0.0248 - mae: 0.1630 - val_loss: 0.1964 - val_mae: 0.6144 - learning_rate: 1.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0227 - mae: 0.1569 - val_loss: 0.1871 - val_mae: 0.5995 - learning_rate: 1.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0217 - mae: 0.1503 - val_loss: 0.1787 - val_mae: 0.5857 - learning_rate: 1.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0212 - mae: 0.1473 - val_loss: 0.1681 - val_mae: 0.5677 - learning_rate: 1.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0188 - mae: 0.1406 - val_loss: 0.1554 - val_mae: 0.5450 - learning_rate: 1.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - loss: 0.0176 - mae: 0.1320 - val_loss: 0.1497 - val_mae: 0.5351 - learning_rate: 1.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - loss: 0.0174 - mae: 0.1326 - val_loss: 0.1261 - val_mae: 0.4893 - learning_rate: 1.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0161 - mae: 0.1244 - val_loss: 0.1163 - val_mae: 0.4694 - learning_rate: 1.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - loss: 0.0165 - mae: 0.1254 - val_loss: 0.1003 - val_mae: 0.4346 - learning_rate: 1.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - loss: 0.0147 - mae: 0.1180 - val_loss: 0.0889 - val_mae: 0.4082 - learning_rate: 1.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0139 - mae: 0.1113 - val_loss: 0.0812 - val_mae: 0.3895 - learning_rate: 1.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - loss: 0.0135 - mae: 0.1122 - val_loss: 0.0789 - val_mae: 0.3840 - learning_rate: 1.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.0127 - mae: 0.1065 - val_loss: 0.0636 - val_mae: 0.3420 - learning_rate: 1.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0114 - mae: 0.1006 - val_loss: 0.0670 - val_mae: 0.3526 - learning_rate: 1.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 0.0129 - mae: 0.1058 - val_loss: 0.0635 - val_mae: 0.3426 - learning_rate: 1.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - loss: 0.0118 - mae: 0.1022 - val_loss: 0.0671 - val_mae: 0.3538 - learning_rate: 1.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0106 - mae: 0.0992 - val_loss: 0.0533 - val_mae: 0.3119 - learning_rate: 1.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - loss: 0.0110 - mae: 0.0988 - val_loss: 0.0617 - val_mae: 0.3383 - learning_rate: 1.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0115 - mae: 0.0982 - val_loss: 0.0644 - val_mae: 0.3460 - learning_rate: 1.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0107 - mae: 0.0959 - val_loss: 0.0657 - val_mae: 0.3498 - learning_rate: 1.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 0.0116 - mae: 0.0993 - val_loss: 0.0624 - val_mae: 0.3399 - learning_rate: 1.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - loss: 0.0116 - mae: 0.0995 - val_loss: 0.0630 - val_mae: 0.3415 - learning_rate: 1.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0114 - mae: 0.0980 - val_loss: 0.0631 - val_mae: 0.3423 - learning_rate: 1.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0109 - mae: 0.0945\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - loss: 0.0109 - mae: 0.0945 - val_loss: 0.0684 - val_mae: 0.3574 - learning_rate: 1.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0108 - mae: 0.0947 - val_loss: 0.0647 - val_mae: 0.3467 - learning_rate: 5.0000e-05\n",
            "Epoch 33/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0105 - mae: 0.0934 - val_loss: 0.0674 - val_mae: 0.3547 - learning_rate: 5.0000e-05\n",
            "Epoch 34/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 0.0117 - mae: 0.0961 - val_loss: 0.0584 - val_mae: 0.3280 - learning_rate: 5.0000e-05\n",
            "Epoch 35/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 0.0110 - mae: 0.0937 - val_loss: 0.0599 - val_mae: 0.3325 - learning_rate: 5.0000e-05\n",
            "Epoch 36/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - loss: 0.0105 - mae: 0.0947 - val_loss: 0.0558 - val_mae: 0.3198 - learning_rate: 5.0000e-05\n",
            "Epoch 37/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - loss: 0.0103 - mae: 0.0939 - val_loss: 0.0596 - val_mae: 0.3319 - learning_rate: 5.0000e-05\n",
            "Epoch 38/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0092 - mae: 0.0871\n",
            "Epoch 38: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0092 - mae: 0.0871 - val_loss: 0.0570 - val_mae: 0.3240 - learning_rate: 5.0000e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0109 - mae: 0.0949 - val_loss: 0.0587 - val_mae: 0.3295 - learning_rate: 2.5000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f2178827260>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run these after training completes\n",
        "pred_mean = predictor.predict_with_uncertainty()\n",
        "sharpe, drawdown, total_return, annual_return = predictor.backtest(pred_mean)\n",
        "print(f\"Sharpe Ratio: {sharpe:.2f}\")\n",
        "print(f\"Max Drawdown: {drawdown:.2%}\")\n",
        "print(f\"Total Return: {total_return:.2%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJfqMFAl4h-3",
        "outputId": "f12ae1e9-b408-400a-f094-93726600d347"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Sharpe Ratio: 0.04\n",
            "Max Drawdown: 13.76%\n",
            "Total Return: -100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_prediction_alignment(self):\n",
        "    pred_mean = self.predict_with_uncertainty()\n",
        "    print(f\"First 5 predictions: {pred_mean[:5]}\")\n",
        "    print(f\"First 5 actual prices: {self.test_data['Close'].values[:5]}\")\n",
        "    print(f\"Prediction range: {pred_mean.min():.2f} to {pred_mean.max():.2f}\")\n",
        "    print(f\"Actual price range: {self.test_data['Close'].values.min():.2f} to {self.test_data['Close'].values.max():.2f}\")"
      ],
      "metadata": {
        "id": "T7ouayxi5YMV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_directional_accuracy(self):\n",
        "    pred_mean = self.predict_with_uncertainty()\n",
        "    actual_next = self.test_data['Close'].values[1:]\n",
        "    pred_next = pred_mean[:-1]\n",
        "\n",
        "    direction_correct = np.mean((actual_next > self.test_data['Close'].values[:-1]) ==\n",
        "                             (pred_next > self.test_data['Close'].values[:-1]))\n",
        "    print(f\"Directional accuracy: {direction_correct:.2%}\")\n",
        "\n",
        "    # Check if predictions are systematically high or low\n",
        "    pred_error = pred_next - self.test_data['Close'].values[:-1]\n",
        "    print(f\"Mean prediction error: {np.mean(pred_error):.4f}\")\n",
        "    print(f\"Prediction error std: {np.std(pred_error):.4f}\")"
      ],
      "metadata": {
        "id": "5QLHfJ9p8LkA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backtest_debug(self, predictions):\n",
        "    test_prices = self.test_data['Close'].values\n",
        "\n",
        "    # Very simple backtest to isolate issues\n",
        "    signals = np.where(predictions[:-1] > test_prices[:-1], 1, -1)\n",
        "    returns = test_prices[1:] / test_prices[:-1] - 1\n",
        "    strategy_returns = signals * returns\n",
        "\n",
        "    print(f\"Number of long signals: {np.sum(signals == 1)}\")\n",
        "    print(f\"Number of short signals: {np.sum(signals == -1)}\")\n",
        "    print(f\"Number of no positions: {np.sum(signals == 0)}\")\n",
        "    print(f\"Mean strategy return: {np.mean(strategy_returns):.4f}\")\n",
        "    print(f\"Mean actual return: {np.mean(returns):.4f}\")"
      ],
      "metadata": {
        "id": "FDIredYD8SRJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HT4r-rOd9Ahz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}