{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2O3OnsfY2+mOeJs1YkjGl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PierreBond/SP_PREDICTOR/blob/main/predictor2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iXHcb-9S1hCf",
        "outputId": "0178c7fd-7490-4669-cc0e-53d6cdc9d564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.12/dist-packages (0.2.66)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.5.1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.4.7)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.12/dist-packages (from yfinance) (3.18.3)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.13.5)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.13.0)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2025.11.12)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.23)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install numpy pandas matplotlib scikit-learn tensorflow yfinance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, LayerNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "jtMK9DnG2XBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StockPredictor:\n",
        "    def __init__(self, ticker, seq_length=60, epochs=50):\n",
        "        if not isinstance(ticker, str) or len(ticker) == 0:\n",
        "            raise ValueError(\"Ticker must be a non-empty string\")\n",
        "        self.ticker = ticker\n",
        "        self.seq_length = seq_length\n",
        "        self.epochs = epochs\n",
        "        self.scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        self.model = None\n",
        "        self.data = None\n",
        "        self.X_test = None\n",
        "        self.y_test = None\n",
        "        self.split_idx = None\n",
        "        self.test_data = None\n",
        "        self.close_scaler = None\n",
        "\n",
        "    def fetch_data(self, start='2010-01-01', end='2023-12-31'):\n",
        "        \"\"\"Fetch OHLCV data with error handling.\"\"\"\n",
        "        try:\n",
        "            self.data = yf.download(self.ticker, start=start, end=end)\n",
        "            if self.data.empty:\n",
        "                raise ValueError(f\"No data found for ticker: {self.ticker}\")\n",
        "            self.data['Returns'] = self.data['Close'].pct_change()\n",
        "            self.data['RSI'] = self._compute_rsi(self.data['Close'], window=14)\n",
        "            self.data['MACD'] = self.data['Close'].ewm(span=12).mean() - self.data['Close'].ewm(span=26).mean()\n",
        "            self.data.dropna(inplace=True)\n",
        "            return self.data\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching data: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _compute_rsi(self, series, window=14):\n",
        "        delta = series.diff()\n",
        "        gain = (delta.where(delta > 0, 0)).rolling(window).mean()\n",
        "        loss = (-delta.where(delta < 0, 0)).rolling(window).mean()\n",
        "        return 100 - (100 / (1 + gain / loss))\n",
        "\n",
        "    def preprocess_data(self):\n",
        "        \"\"\"Split before scaling to prevent leakage.\"\"\"\n",
        "        # Start with simpler features for better generalization\n",
        "        features = self.data[['Close', 'Volume', 'RSI']].values  # Simplified feature set\n",
        "\n",
        "        self.split_idx = int(0.8 * len(features))\n",
        "        train_features, test_features = features[:self.split_idx], features[self.split_idx:]\n",
        "\n",
        "        train_scaled = self.scaler.fit_transform(train_features)\n",
        "        test_scaled = self.scaler.transform(test_features)\n",
        "\n",
        "        X_train, y_train = self._create_sequences(train_scaled)\n",
        "        X_test, y_test = self._create_sequences(test_scaled)\n",
        "\n",
        "        self.X_test, self.y_test = X_test, y_test\n",
        "        self.test_data = self.data.iloc[self.split_idx + self.seq_length:]\n",
        "        self.close_scaler = MinMaxScaler()  # Separate scaler for inverse transform\n",
        "        self.close_scaler.fit(features[:, 0].reshape(-1, 1))\n",
        "\n",
        "        return X_train, X_test, y_train, y_test\n",
        "\n",
        "    def _create_sequences(self, data):\n",
        "        X, y = [], []\n",
        "        for i in range(len(data) - self.seq_length):\n",
        "            X.append(data[i:i+self.seq_length])\n",
        "            y.append(data[i+self.seq_length, 0])\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    def create_simpler_model(self):\n",
        "        \"\"\"Simplified LSTM model without attention for better generalization.\"\"\"\n",
        "        inputs = Input(shape=(self.seq_length, 3))  # 3 features: Close, Volume, RSI\n",
        "\n",
        "        # Simplified architecture with regularization\n",
        "        x = LSTM(32, return_sequences=True, dropout=0.3)(inputs)\n",
        "        x = LayerNormalization()(x)\n",
        "        x = LSTM(16, dropout=0.3)(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "\n",
        "        outputs = Dense(1)(x)\n",
        "\n",
        "        model = Model(inputs, outputs)\n",
        "        model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "            loss='huber',\n",
        "            metrics=['mae']\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def train(self):\n",
        "        X_train, X_test, y_train, y_test = self.preprocess_data()\n",
        "        self.model = self.create_simpler_model()\n",
        "\n",
        "        callbacks = [\n",
        "            EarlyStopping(patience=15, restore_best_weights=True, monitor='val_loss', min_delta=0.001),\n",
        "            ReduceLROnPlateau(factor=0.5, patience=7, min_lr=1e-7, monitor='val_loss', verbose=1)\n",
        "        ]\n",
        "\n",
        "        history = self.model.fit(\n",
        "            X_train, y_train,\n",
        "            epochs=self.epochs,\n",
        "            batch_size=32,\n",
        "            validation_data=(X_test, y_test),\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "        return history\n",
        "\n",
        "    def predict_with_uncertainty(self, n_samples=10):\n",
        "        \"\"\"Monte Carlo dropout for uncertainty estimation.\"\"\"\n",
        "        mc_predictions = np.stack([self.model.predict(self.X_test) for _ in range(n_samples)])\n",
        "        mean = mc_predictions.mean(axis=0)\n",
        "\n",
        "        # Inverse transform only the close price\n",
        "        dummy = np.zeros((len(mean), 3))\n",
        "        dummy[:, 0] = mean.flatten()\n",
        "        predictions = self.close_scaler.inverse_transform(dummy)[:, 0]\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def backtest(self, predictions, threshold=0.001):  # Reduced threshold\n",
        "        \"\"\"Robust backtesting with proper data alignment.\"\"\"\n",
        "        test_prices = self.test_data['Close'].values\n",
        "\n",
        "        min_len = min(len(predictions), len(test_prices))\n",
        "        predictions = predictions[:min_len]\n",
        "        test_prices = test_prices[:min_len]\n",
        "\n",
        "        # More conservative signal generation\n",
        "        signals = np.where(predictions[:-1] > test_prices[:-1] * (1 + threshold), 1, -1)\n",
        "        returns = test_prices[1:] / test_prices[:-1] - 1\n",
        "        strategy_returns = signals * returns - 0.001  # Transaction cost\n",
        "\n",
        "        # Calculate metrics\n",
        "        sharpe = np.sqrt(252) * strategy_returns.mean() / strategy_returns.std()\n",
        "        max_drawdown = (np.maximum.accumulate(1 + strategy_returns) - (1 + strategy_returns)).max()\n",
        "        total_return = np.prod(1 + strategy_returns) - 1\n",
        "        annual_return = (1 + total_return) ** (252 / len(strategy_returns)) - 1\n",
        "\n",
        "        return sharpe, max_drawdown, total_return, annual_return\n",
        "\n",
        "    def plot_results(self):\n",
        "        \"\"\"Plot with properly aligned data and uncertainty bands.\"\"\"\n",
        "        if self.test_data is None:\n",
        "            raise ValueError(\"Test data not available. Run preprocess_data() first.\")\n",
        "\n",
        "        pred_mean = self.predict_with_uncertainty()\n",
        "\n",
        "        plt.figure(figsize=(14, 8))\n",
        "\n",
        "        # Price plot\n",
        "        plt.subplot(2, 1, 1)\n",
        "        plt.plot(self.test_data.index, self.test_data['Close'].values,\n",
        "                label='True Price', linewidth=2)\n",
        "        plt.plot(self.test_data.index, pred_mean, label='Predicted', alpha=0.8)\n",
        "        plt.title(f\"{self.ticker} Stock Price Prediction\")\n",
        "        plt.ylabel(\"Price ($)\")\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        # Returns distribution\n",
        "        plt.subplot(2, 1, 2)\n",
        "        test_returns = self.test_data['Returns'].values\n",
        "        plt.hist(test_returns, bins=50, alpha=0.7, edgecolor='black', color='skyblue')\n",
        "        plt.axvline(np.mean(test_returns), color='red', linestyle='--',\n",
        "                   label=f'Mean: {np.mean(test_returns):.2%}')\n",
        "        plt.title(\"Returns Distribution\")\n",
        "        plt.ylabel(\"Frequency\")\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def evaluate_diagnostics(self):\n",
        "        \"\"\"Additional diagnostics to understand model performance.\"\"\"\n",
        "        pred_mean = self.predict_with_uncertainty()\n",
        "\n",
        "        # Check alignment\n",
        "        print(f\"Prediction length: {len(pred_mean)}\")\n",
        "        print(f\"Test prices length: {len(self.test_data['Close'])}\")\n",
        "\n",
        "        # Directional accuracy\n",
        "        actual_next = self.test_data['Close'].values[1:]\n",
        "        pred_next = pred_mean[:-1]\n",
        "        direction_correct = np.mean((actual_next > self.test_data['Close'].values[:-1]) ==\n",
        "                                 (pred_next > self.test_data['Close'].values[:-1]))\n",
        "        print(f\"Directional accuracy: {direction_correct:.2%}\")\n",
        "\n",
        "        # Basic error metrics\n",
        "        rmse = np.sqrt(mean_squared_error(self.test_data['Close'].values[1:], pred_next))\n",
        "        print(f\"RMSE: ${rmse:.2f}\")\n",
        "\n",
        "        return direction_correct, rmse\n"
      ],
      "metadata": {
        "id": "NSqIRvF312hY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "        # Initialize and train\n",
        "        predictor = StockPredictor(\"AAPL\", seq_length=60, epochs=50)\n",
        "        predictor.fetch_data()\n",
        "        predictor.train()"
      ],
      "metadata": {
        "id": "YGN_263v2FrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run these after training completes\n",
        "pred_mean = predictor.predict_with_uncertainty()\n",
        "sharpe, drawdown, total_return, annual_return = predictor.backtest(pred_mean)\n",
        "print(f\"Sharpe Ratio: {sharpe:.2f}\")\n",
        "print(f\"Max Drawdown: {drawdown:.2%}\")\n",
        "print(f\"Total Return: {total_return:.2%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uJfqMFAl4h-3",
        "outputId": "47830e10-1a5f-4fcc-9b7b-79ef6164c355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Sharpe Ratio: -0.08\n",
            "Max Drawdown: 13.76%\n",
            "Total Return: -100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_prediction_alignment(self):\n",
        "    pred_mean = self.predict_with_uncertainty()\n",
        "    print(f\"First 5 predictions: {pred_mean[:5]}\")\n",
        "    print(f\"First 5 actual prices: {self.test_data['Close'].values[:5]}\")\n",
        "    print(f\"Prediction range: {pred_mean.min():.2f} to {pred_mean.max():.2f}\")\n",
        "    print(f\"Actual price range: {self.test_data['Close'].values.min():.2f} to {self.test_data['Close'].values.max():.2f}\")"
      ],
      "metadata": {
        "id": "T7ouayxi5YMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_directional_accuracy(self):\n",
        "    pred_mean = self.predict_with_uncertainty()\n",
        "    actual_next = self.test_data['Close'].values[1:]\n",
        "    pred_next = pred_mean[:-1]\n",
        "\n",
        "    direction_correct = np.mean((actual_next > self.test_data['Close'].values[:-1]) ==\n",
        "                             (pred_next > self.test_data['Close'].values[:-1]))\n",
        "    print(f\"Directional accuracy: {direction_correct:.2%}\")\n",
        "\n",
        "    # Check if predictions are systematically high or low\n",
        "    pred_error = pred_next - self.test_data['Close'].values[:-1]\n",
        "    print(f\"Mean prediction error: {np.mean(pred_error):.4f}\")\n",
        "    print(f\"Prediction error std: {np.std(pred_error):.4f}\")"
      ],
      "metadata": {
        "id": "5QLHfJ9p8LkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backtest_debug(self, predictions):\n",
        "    test_prices = self.test_data['Close'].values\n",
        "\n",
        "    # Very simple backtest to isolate issues\n",
        "    signals = np.where(predictions[:-1] > test_prices[:-1], 1, -1)\n",
        "    returns = test_prices[1:] / test_prices[:-1] - 1\n",
        "    strategy_returns = signals * returns\n",
        "\n",
        "    print(f\"Number of long signals: {np.sum(signals == 1)}\")\n",
        "    print(f\"Number of short signals: {np.sum(signals == -1)}\")\n",
        "    print(f\"Number of no positions: {np.sum(signals == 0)}\")\n",
        "    print(f\"Mean strategy return: {np.mean(strategy_returns):.4f}\")\n",
        "    print(f\"Mean actual return: {np.mean(returns):.4f}\")"
      ],
      "metadata": {
        "id": "FDIredYD8SRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Initialize and train\n",
        "        predictor = StockPredictor(\"AAPL\", seq_length=60, epochs=50)\n",
        "        predictor.fetch_data()\n",
        "        predictor.train()\n",
        "\n",
        "        # Run comprehensive evaluation\n",
        "        predictor.plot_diagnostics()\n",
        "\n",
        "        # Print key metrics\n",
        "        pred_mean = predictor.predict_with_uncertainty()\n",
        "        sharpe, drawdown, total_return, annual_return = predictor.backtest(pred_mean)\n",
        "        direction_acc, rmse = predictor.evaluate_diagnostics()\n",
        "\n",
        "        print(\"\\n=== Performance Metrics ===\")\n",
        "        print(f\"Sharpe Ratio: {sharpe:.2f}\")\n",
        "        print(f\"Max Drawdown: {drawdown:.2%}\")\n",
        "        print(f\"Total Return: {total_return:.2%}\")\n",
        "        print(f\"Annual Return: {annual_return:.2%}\")\n",
        "        print(f\"Directional Accuracy: {direction_acc:.2%}\")\n",
        "        print(f\"RMSE: ${rmse:.2f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")"
      ],
      "metadata": {
        "id": "GE07FN9scYa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_very_simple_model(self):\n",
        "    inputs = Input(shape=(self.seq_length, 3))\n",
        "    x = LSTM(16, dropout=0.4)(inputs)\n",
        "    outputs = Dense(1)(x)\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model"
      ],
      "metadata": {
        "id": "HT4r-rOd9Ahz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After training completes\n",
        "pred_mean = predictor.predict_with_uncertainty()\n",
        "sharpe, drawdown, total_return, annual_return = predictor.backtest(pred_mean)\n",
        "direction_acc, rmse = predictor.evaluate_diagnostics()"
      ],
      "metadata": {
        "id": "Ld1Kp-sTzAVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_very_simple_model(self):\n",
        "    inputs = Input(shape=(self.seq_length, 3))\n",
        "    x = LSTM(16, dropout=0.4)(inputs)\n",
        "    outputs = Dense(1)(x)\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model"
      ],
      "metadata": {
        "id": "pgPrEX_zzAso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_prediction_quality(self):\n",
        "    pred_mean = self.predict_with_uncertainty()\n",
        "    actual = self.test_data['Close'].values\n",
        "\n",
        "    # Check if predictions are systematically high or low\n",
        "    pred_error = pred_mean - actual\n",
        "    print(f\"Mean prediction error: {np.mean(pred_error):.2f}\")\n",
        "    print(f\"Prediction error std: {np.std(pred_error):.2f}\")\n",
        "\n",
        "    # Check if predictions follow trends\n",
        "    trend_correct = np.mean(np.sign(np.diff(pred_mean)) == np.sign(np.diff(actual)))\n",
        "    print(f\"Trend accuracy: {trend_correct:.2%}\")"
      ],
      "metadata": {
        "id": "G42ZSNJgz8Yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_predictions(self):\n",
        "    pred_mean = self.predict_with_uncertainty()\n",
        "    actual = self.test_data['Close'].values\n",
        "\n",
        "    # Check systematic bias\n",
        "    pred_error = pred_mean - actual\n",
        "    print(f\"Mean prediction error: {np.mean(pred_error):.2f}\")\n",
        "    print(f\"Error std: {np.std(pred_error):.2f}\")\n",
        "\n",
        "    # Check trend following\n",
        "    trend_correct = np.mean(np.sign(np.diff(pred_mean)) == np.sign(np.diff(actual)))\n",
        "    print(f\"Trend accuracy: {trend_correct:.2%}\")\n",
        "\n",
        "    # Plot predictions vs actual\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(actual, label='Actual')\n",
        "    plt.plot(pred_mean, label='Predicted', alpha=0.7)\n",
        "    plt.legend()\n",
        "    plt.title('Predictions vs Actual')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "o6VcWKOh07Xs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}