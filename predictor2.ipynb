{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfYiST0viD5t8ioxGgpud+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PierreBond/SP_PREDICTOR/blob/main/predictor2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iXHcb-9S1hCf",
        "outputId": "0178c7fd-7490-4669-cc0e-53d6cdc9d564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.12/dist-packages (0.2.66)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.5.1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.4.7)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.12/dist-packages (from yfinance) (3.18.3)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.13.5)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.13.0)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2025.11.12)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.23)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install numpy pandas matplotlib scikit-learn tensorflow yfinance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, LayerNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "jtMK9DnG2XBh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StockPredictor:\n",
        "    def __init__(self, ticker, seq_length=60, epochs=50):\n",
        "        if not isinstance(ticker, str) or len(ticker) == 0:\n",
        "            raise ValueError(\"Ticker must be a non-empty string\")\n",
        "        self.ticker = ticker\n",
        "        self.seq_length = seq_length\n",
        "        self.epochs = epochs\n",
        "        self.scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        self.model = None\n",
        "        self.data = None\n",
        "        self.X_test = None\n",
        "        self.y_test = None\n",
        "        self.split_idx = None\n",
        "        self.test_data = None\n",
        "        self.close_scaler = None\n",
        "\n",
        "    def fetch_data(self, start='2010-01-01', end='2023-12-31'):\n",
        "        \"\"\"Fetch OHLCV data with error handling.\"\"\"\n",
        "        try:\n",
        "            self.data = yf.download(self.ticker, start=start, end=end)\n",
        "            if self.data.empty:\n",
        "                raise ValueError(f\"No data found for ticker: {self.ticker}\")\n",
        "            self.data['Returns'] = self.data['Close'].pct_change()\n",
        "            self.data['RSI'] = self._compute_rsi(self.data['Close'], window=14)\n",
        "            self.data['MACD'] = self.data['Close'].ewm(span=12).mean() - self.data['Close'].ewm(span=26).mean()\n",
        "            self.data.dropna(inplace=True)\n",
        "            return self.data\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching data: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _compute_rsi(self, series, window=14):\n",
        "        delta = series.diff()\n",
        "        gain = (delta.where(delta > 0, 0)).rolling(window).mean()\n",
        "        loss = (-delta.where(delta < 0, 0)).rolling(window).mean()\n",
        "        return 100 - (100 / (1 + gain / loss))\n",
        "\n",
        "    def preprocess_data(self):\n",
        "        \"\"\"Split before scaling to prevent leakage.\"\"\"\n",
        "        # Start with simpler features for better generalization\n",
        "        features = self.data[['Close', 'Volume', 'RSI']].values  # Simplified feature set\n",
        "\n",
        "        self.split_idx = int(0.8 * len(features))\n",
        "        train_features, test_features = features[:self.split_idx], features[self.split_idx:]\n",
        "\n",
        "        train_scaled = self.scaler.fit_transform(train_features)\n",
        "        test_scaled = self.scaler.transform(test_features)\n",
        "\n",
        "        X_train, y_train = self._create_sequences(train_scaled)\n",
        "        X_test, y_test = self._create_sequences(test_scaled)\n",
        "\n",
        "        self.X_test, self.y_test = X_test, y_test\n",
        "        self.test_data = self.data.iloc[self.split_idx + self.seq_length:]\n",
        "        self.close_scaler = MinMaxScaler()  # Separate scaler for inverse transform\n",
        "        self.close_scaler.fit(features[:, 0].reshape(-1, 1))\n",
        "\n",
        "        return X_train, X_test, y_train, y_test\n",
        "\n",
        "    def _create_sequences(self, data):\n",
        "        X, y = [], []\n",
        "        for i in range(len(data) - self.seq_length):\n",
        "            X.append(data[i:i+self.seq_length])\n",
        "            y.append(data[i+self.seq_length, 0])\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    def create_simpler_model(self):\n",
        "        \"\"\"Simplified LSTM model without attention for better generalization.\"\"\"\n",
        "        inputs = Input(shape=(self.seq_length, 3))  # 3 features: Close, Volume, RSI\n",
        "\n",
        "        # Simplified architecture with regularization\n",
        "        x = LSTM(32, return_sequences=True, dropout=0.3)(inputs)\n",
        "        x = LayerNormalization()(x)\n",
        "        x = LSTM(16, dropout=0.3)(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "\n",
        "        outputs = Dense(1)(x)\n",
        "\n",
        "        model = Model(inputs, outputs)\n",
        "        model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "            loss='huber',\n",
        "            metrics=['mae']\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def train(self):\n",
        "        X_train, X_test, y_train, y_test = self.preprocess_data()\n",
        "        self.model = self.create_simpler_model()\n",
        "\n",
        "        callbacks = [\n",
        "            EarlyStopping(patience=15, restore_best_weights=True, monitor='val_loss', min_delta=0.001),\n",
        "            ReduceLROnPlateau(factor=0.5, patience=7, min_lr=1e-7, monitor='val_loss', verbose=1)\n",
        "        ]\n",
        "\n",
        "        history = self.model.fit(\n",
        "            X_train, y_train,\n",
        "            epochs=self.epochs,\n",
        "            batch_size=32,\n",
        "            validation_data=(X_test, y_test),\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "        return history\n",
        "\n",
        "    def predict_with_uncertainty(self, n_samples=10):\n",
        "        \"\"\"Monte Carlo dropout for uncertainty estimation.\"\"\"\n",
        "        mc_predictions = np.stack([self.model.predict(self.X_test) for _ in range(n_samples)])\n",
        "        mean = mc_predictions.mean(axis=0)\n",
        "\n",
        "        # Inverse transform only the close price\n",
        "        dummy = np.zeros((len(mean), 3))\n",
        "        dummy[:, 0] = mean.flatten()\n",
        "        predictions = self.close_scaler.inverse_transform(dummy)[:, 0]\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def backtest(self, predictions, threshold=0.001):  # Reduced threshold\n",
        "        \"\"\"Robust backtesting with proper data alignment.\"\"\"\n",
        "        test_prices = self.test_data['Close'].values\n",
        "\n",
        "        min_len = min(len(predictions), len(test_prices))\n",
        "        predictions = predictions[:min_len]\n",
        "        test_prices = test_prices[:min_len]\n",
        "\n",
        "        # More conservative signal generation\n",
        "        signals = np.where(predictions[:-1] > test_prices[:-1] * (1 + threshold), 1, -1)\n",
        "        returns = test_prices[1:] / test_prices[:-1] - 1\n",
        "        strategy_returns = signals * returns - 0.001  # Transaction cost\n",
        "\n",
        "        # Calculate metrics\n",
        "        sharpe = np.sqrt(252) * strategy_returns.mean() / strategy_returns.std()\n",
        "        max_drawdown = (np.maximum.accumulate(1 + strategy_returns) - (1 + strategy_returns)).max()\n",
        "        total_return = np.prod(1 + strategy_returns) - 1\n",
        "        annual_return = (1 + total_return) ** (252 / len(strategy_returns)) - 1\n",
        "\n",
        "        return sharpe, max_drawdown, total_return, annual_return\n",
        "\n",
        "    def plot_results(self):\n",
        "        \"\"\"Plot with properly aligned data and uncertainty bands.\"\"\"\n",
        "        if self.test_data is None:\n",
        "            raise ValueError(\"Test data not available. Run preprocess_data() first.\")\n",
        "\n",
        "        pred_mean = self.predict_with_uncertainty()\n",
        "\n",
        "        plt.figure(figsize=(14, 8))\n",
        "\n",
        "        # Price plot\n",
        "        plt.subplot(2, 1, 1)\n",
        "        plt.plot(self.test_data.index, self.test_data['Close'].values,\n",
        "                label='True Price', linewidth=2)\n",
        "        plt.plot(self.test_data.index, pred_mean, label='Predicted', alpha=0.8)\n",
        "        plt.title(f\"{self.ticker} Stock Price Prediction\")\n",
        "        plt.ylabel(\"Price ($)\")\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        # Returns distribution\n",
        "        plt.subplot(2, 1, 2)\n",
        "        test_returns = self.test_data['Returns'].values\n",
        "        plt.hist(test_returns, bins=50, alpha=0.7, edgecolor='black', color='skyblue')\n",
        "        plt.axvline(np.mean(test_returns), color='red', linestyle='--',\n",
        "                   label=f'Mean: {np.mean(test_returns):.2%}')\n",
        "        plt.title(\"Returns Distribution\")\n",
        "        plt.ylabel(\"Frequency\")\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def evaluate_diagnostics(self):\n",
        "        \"\"\"Additional diagnostics to understand model performance.\"\"\"\n",
        "        pred_mean = self.predict_with_uncertainty()\n",
        "\n",
        "        # Check alignment\n",
        "        print(f\"Prediction length: {len(pred_mean)}\")\n",
        "        print(f\"Test prices length: {len(self.test_data['Close'])}\")\n",
        "\n",
        "        # Directional accuracy\n",
        "        actual_next = self.test_data['Close'].values[1:]\n",
        "        pred_next = pred_mean[:-1]\n",
        "        direction_correct = np.mean((actual_next > self.test_data['Close'].values[:-1]) ==\n",
        "                                 (pred_next > self.test_data['Close'].values[:-1]))\n",
        "        print(f\"Directional accuracy: {direction_correct:.2%}\")\n",
        "\n",
        "        # Basic error metrics\n",
        "        rmse = np.sqrt(mean_squared_error(self.test_data['Close'].values[1:], pred_next))\n",
        "        print(f\"RMSE: ${rmse:.2f}\")\n",
        "\n",
        "        return direction_correct, rmse\n",
        ""
      ],
      "metadata": {
        "id": "NSqIRvF312hY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "        # Initialize and train\n",
        "        predictor = StockPredictor(\"AAPL\", seq_length=60, epochs=50)\n",
        "        predictor.fetch_data()\n",
        "        predictor.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGN_263v2FrO",
        "outputId": "4823aa77-b1e5-4bef-dd87-e7fd5b744cc0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3092242290.py:20: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  self.data = yf.download(self.ticker, start=start, end=end)\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 46ms/step - loss: 0.0919 - mae: 0.3353 - val_loss: 0.2838 - val_mae: 0.7431 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0544 - mae: 0.2600 - val_loss: 0.2783 - val_mae: 0.7361 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - loss: 0.0485 - mae: 0.2375 - val_loss: 0.2775 - val_mae: 0.7353 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0395 - mae: 0.2139 - val_loss: 0.2770 - val_mae: 0.7349 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - loss: 0.0349 - mae: 0.2015 - val_loss: 0.2810 - val_mae: 0.7406 - learning_rate: 1.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0305 - mae: 0.1845 - val_loss: 0.2779 - val_mae: 0.7366 - learning_rate: 1.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0287 - mae: 0.1796 - val_loss: 0.2657 - val_mae: 0.7203 - learning_rate: 1.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - loss: 0.0267 - mae: 0.1705 - val_loss: 0.2556 - val_mae: 0.7066 - learning_rate: 1.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0238 - mae: 0.1555 - val_loss: 0.2332 - val_mae: 0.6748 - learning_rate: 1.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0200 - mae: 0.1454 - val_loss: 0.2028 - val_mae: 0.6289 - learning_rate: 1.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - loss: 0.0196 - mae: 0.1402 - val_loss: 0.1767 - val_mae: 0.5868 - learning_rate: 1.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0211 - mae: 0.1426 - val_loss: 0.1542 - val_mae: 0.5477 - learning_rate: 1.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0161 - mae: 0.1264 - val_loss: 0.1258 - val_mae: 0.4932 - learning_rate: 1.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - loss: 0.0173 - mae: 0.1285 - val_loss: 0.1173 - val_mae: 0.4765 - learning_rate: 1.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0147 - mae: 0.1190 - val_loss: 0.1162 - val_mae: 0.4745 - learning_rate: 1.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - loss: 0.0150 - mae: 0.1163 - val_loss: 0.1015 - val_mae: 0.4422 - learning_rate: 1.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - loss: 0.0141 - mae: 0.1147 - val_loss: 0.1010 - val_mae: 0.4413 - learning_rate: 1.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - loss: 0.0131 - mae: 0.1090 - val_loss: 0.0939 - val_mae: 0.4250 - learning_rate: 1.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0135 - mae: 0.1094 - val_loss: 0.0777 - val_mae: 0.3843 - learning_rate: 1.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - loss: 0.0134 - mae: 0.1076 - val_loss: 0.0852 - val_mae: 0.4036 - learning_rate: 1.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0119 - mae: 0.1037 - val_loss: 0.0760 - val_mae: 0.3789 - learning_rate: 1.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0123 - mae: 0.1042 - val_loss: 0.0731 - val_mae: 0.3710 - learning_rate: 1.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - loss: 0.0112 - mae: 0.1019 - val_loss: 0.0773 - val_mae: 0.3823 - learning_rate: 1.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0119 - mae: 0.1021 - val_loss: 0.0736 - val_mae: 0.3722 - learning_rate: 1.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0118 - mae: 0.0994 - val_loss: 0.0736 - val_mae: 0.3721 - learning_rate: 1.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - loss: 0.0134 - mae: 0.1040 - val_loss: 0.0774 - val_mae: 0.3823 - learning_rate: 1.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0118 - mae: 0.1001 - val_loss: 0.0718 - val_mae: 0.3669 - learning_rate: 1.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0113 - mae: 0.0997 - val_loss: 0.0784 - val_mae: 0.3845 - learning_rate: 1.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - loss: 0.0120 - mae: 0.1001 - val_loss: 0.0711 - val_mae: 0.3642 - learning_rate: 1.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0109 - mae: 0.0955 - val_loss: 0.0700 - val_mae: 0.3611 - learning_rate: 1.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0125 - mae: 0.1006 - val_loss: 0.0717 - val_mae: 0.3657 - learning_rate: 1.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - loss: 0.0111 - mae: 0.0947 - val_loss: 0.0687 - val_mae: 0.3573 - learning_rate: 1.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0110 - mae: 0.0962 - val_loss: 0.0654 - val_mae: 0.3475 - learning_rate: 1.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - loss: 0.0114 - mae: 0.0956 - val_loss: 0.0726 - val_mae: 0.3680 - learning_rate: 1.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0103 - mae: 0.0946 - val_loss: 0.0708 - val_mae: 0.3629 - learning_rate: 1.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0113 - mae: 0.0943 - val_loss: 0.0778 - val_mae: 0.3822 - learning_rate: 1.0000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0107 - mae: 0.0958 - val_loss: 0.0732 - val_mae: 0.3698 - learning_rate: 1.0000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 0.0116 - mae: 0.0965 - val_loss: 0.0834 - val_mae: 0.3967 - learning_rate: 1.0000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0104 - mae: 0.0920 - val_loss: 0.0745 - val_mae: 0.3735 - learning_rate: 1.0000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0094 - mae: 0.0899\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0094 - mae: 0.0899 - val_loss: 0.0658 - val_mae: 0.3490 - learning_rate: 1.0000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - loss: 0.0103 - mae: 0.0925 - val_loss: 0.0661 - val_mae: 0.3504 - learning_rate: 5.0000e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0103 - mae: 0.0926 - val_loss: 0.0643 - val_mae: 0.3454 - learning_rate: 5.0000e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0107 - mae: 0.0938 - val_loss: 0.0668 - val_mae: 0.3522 - learning_rate: 5.0000e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - loss: 0.0101 - mae: 0.0916 - val_loss: 0.0692 - val_mae: 0.3593 - learning_rate: 5.0000e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0104 - mae: 0.0919 - val_loss: 0.0685 - val_mae: 0.3570 - learning_rate: 5.0000e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0100 - mae: 0.0907 - val_loss: 0.0690 - val_mae: 0.3583 - learning_rate: 5.0000e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - loss: 0.0090 - mae: 0.0874 - val_loss: 0.0759 - val_mae: 0.3773 - learning_rate: 5.0000e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0115 - mae: 0.0941 - val_loss: 0.0685 - val_mae: 0.3567 - learning_rate: 5.0000e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0112 - mae: 0.0941\n",
            "Epoch 49: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0112 - mae: 0.0940 - val_loss: 0.0673 - val_mae: 0.3533 - learning_rate: 5.0000e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0098 - mae: 0.0895 - val_loss: 0.0667 - val_mae: 0.3517 - learning_rate: 2.5000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e057d8612e0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run these after training completes\n",
        "pred_mean = predictor.predict_with_uncertainty()\n",
        "sharpe, drawdown, total_return, annual_return = predictor.backtest(pred_mean)\n",
        "print(f\"Sharpe Ratio: {sharpe:.2f}\")\n",
        "print(f\"Max Drawdown: {drawdown:.2%}\")\n",
        "print(f\"Total Return: {total_return:.2%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uJfqMFAl4h-3",
        "outputId": "47830e10-1a5f-4fcc-9b7b-79ef6164c355"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Sharpe Ratio: -0.08\n",
            "Max Drawdown: 13.76%\n",
            "Total Return: -100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_prediction_alignment(self):\n",
        "    pred_mean = self.predict_with_uncertainty()\n",
        "    print(f\"First 5 predictions: {pred_mean[:5]}\")\n",
        "    print(f\"First 5 actual prices: {self.test_data['Close'].values[:5]}\")\n",
        "    print(f\"Prediction range: {pred_mean.min():.2f} to {pred_mean.max():.2f}\")\n",
        "    print(f\"Actual price range: {self.test_data['Close'].values.min():.2f} to {self.test_data['Close'].values.max():.2f}\")"
      ],
      "metadata": {
        "id": "T7ouayxi5YMV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_directional_accuracy(self):\n",
        "    pred_mean = self.predict_with_uncertainty()\n",
        "    actual_next = self.test_data['Close'].values[1:]\n",
        "    pred_next = pred_mean[:-1]\n",
        "\n",
        "    direction_correct = np.mean((actual_next > self.test_data['Close'].values[:-1]) ==\n",
        "                             (pred_next > self.test_data['Close'].values[:-1]))\n",
        "    print(f\"Directional accuracy: {direction_correct:.2%}\")\n",
        "\n",
        "    # Check if predictions are systematically high or low\n",
        "    pred_error = pred_next - self.test_data['Close'].values[:-1]\n",
        "    print(f\"Mean prediction error: {np.mean(pred_error):.4f}\")\n",
        "    print(f\"Prediction error std: {np.std(pred_error):.4f}\")"
      ],
      "metadata": {
        "id": "5QLHfJ9p8LkA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backtest_debug(self, predictions):\n",
        "    test_prices = self.test_data['Close'].values\n",
        "\n",
        "    # Very simple backtest to isolate issues\n",
        "    signals = np.where(predictions[:-1] > test_prices[:-1], 1, -1)\n",
        "    returns = test_prices[1:] / test_prices[:-1] - 1\n",
        "    strategy_returns = signals * returns\n",
        "\n",
        "    print(f\"Number of long signals: {np.sum(signals == 1)}\")\n",
        "    print(f\"Number of short signals: {np.sum(signals == -1)}\")\n",
        "    print(f\"Number of no positions: {np.sum(signals == 0)}\")\n",
        "    print(f\"Mean strategy return: {np.mean(strategy_returns):.4f}\")\n",
        "    print(f\"Mean actual return: {np.mean(returns):.4f}\")"
      ],
      "metadata": {
        "id": "FDIredYD8SRJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Initialize and train\n",
        "        predictor = StockPredictor(\"AAPL\", seq_length=60, epochs=50)\n",
        "        predictor.fetch_data()\n",
        "        predictor.train()\n",
        "\n",
        "        # Run comprehensive evaluation\n",
        "        predictor.plot_diagnostics()\n",
        "\n",
        "        # Print key metrics\n",
        "        pred_mean = predictor.predict_with_uncertainty()\n",
        "        sharpe, drawdown, total_return, annual_return = predictor.backtest(pred_mean)\n",
        "        direction_acc, rmse = predictor.evaluate_diagnostics()\n",
        "\n",
        "        print(\"\\n=== Performance Metrics ===\")\n",
        "        print(f\"Sharpe Ratio: {sharpe:.2f}\")\n",
        "        print(f\"Max Drawdown: {drawdown:.2%}\")\n",
        "        print(f\"Total Return: {total_return:.2%}\")\n",
        "        print(f\"Annual Return: {annual_return:.2%}\")\n",
        "        print(f\"Directional Accuracy: {direction_acc:.2%}\")\n",
        "        print(f\"RMSE: ${rmse:.2f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GE07FN9scYa9",
        "outputId": "cc5083ee-c539-4f80-917a-9c633061f7e2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3092242290.py:20: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  self.data = yf.download(self.ticker, start=start, end=end)\n",
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - loss: 0.2736 - mae: 0.6109 - val_loss: 0.3036 - val_mae: 0.7671 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.1057 - mae: 0.3670 - val_loss: 0.2673 - val_mae: 0.7187 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 0.0792 - mae: 0.3149 - val_loss: 0.2596 - val_mae: 0.7084 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0556 - mae: 0.2621 - val_loss: 0.2519 - val_mae: 0.6978 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0492 - mae: 0.2422 - val_loss: 0.2516 - val_mae: 0.6976 - learning_rate: 1.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - loss: 0.0402 - mae: 0.2176 - val_loss: 0.2525 - val_mae: 0.6992 - learning_rate: 1.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0352 - mae: 0.2007 - val_loss: 0.2405 - val_mae: 0.6819 - learning_rate: 1.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0304 - mae: 0.1861 - val_loss: 0.2494 - val_mae: 0.6951 - learning_rate: 1.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - loss: 0.0271 - mae: 0.1732 - val_loss: 0.2567 - val_mae: 0.7056 - learning_rate: 1.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - loss: 0.0251 - mae: 0.1666 - val_loss: 0.2518 - val_mae: 0.6988 - learning_rate: 1.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0232 - mae: 0.1570 - val_loss: 0.2404 - val_mae: 0.6827 - learning_rate: 1.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - loss: 0.0226 - mae: 0.1542 - val_loss: 0.2323 - val_mae: 0.6710 - learning_rate: 1.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.0224 - mae: 0.1515 - val_loss: 0.2282 - val_mae: 0.6653 - learning_rate: 1.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0188 - mae: 0.1387 - val_loss: 0.2161 - val_mae: 0.6471 - learning_rate: 1.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0198 - mae: 0.1405 - val_loss: 0.1937 - val_mae: 0.6119 - learning_rate: 1.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 0.0187 - mae: 0.1385 - val_loss: 0.1723 - val_mae: 0.5765 - learning_rate: 1.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0177 - mae: 0.1321 - val_loss: 0.1527 - val_mae: 0.5423 - learning_rate: 1.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0167 - mae: 0.1235 - val_loss: 0.1320 - val_mae: 0.5033 - learning_rate: 1.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 0.0155 - mae: 0.1214 - val_loss: 0.1061 - val_mae: 0.4496 - learning_rate: 1.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0158 - mae: 0.1196 - val_loss: 0.0987 - val_mae: 0.4339 - learning_rate: 1.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - loss: 0.0149 - mae: 0.1139 - val_loss: 0.0851 - val_mae: 0.4018 - learning_rate: 1.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0126 - mae: 0.1048 - val_loss: 0.0685 - val_mae: 0.3584 - learning_rate: 1.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - loss: 0.0124 - mae: 0.1065 - val_loss: 0.0568 - val_mae: 0.3243 - learning_rate: 1.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - loss: 0.0124 - mae: 0.1031 - val_loss: 0.0665 - val_mae: 0.3540 - learning_rate: 1.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0122 - mae: 0.1028 - val_loss: 0.0618 - val_mae: 0.3404 - learning_rate: 1.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0127 - mae: 0.1041 - val_loss: 0.0670 - val_mae: 0.3552 - learning_rate: 1.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - loss: 0.0118 - mae: 0.1011 - val_loss: 0.0503 - val_mae: 0.3038 - learning_rate: 1.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.0122 - mae: 0.1013 - val_loss: 0.0512 - val_mae: 0.3067 - learning_rate: 1.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0109 - mae: 0.0971 - val_loss: 0.0531 - val_mae: 0.3128 - learning_rate: 1.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - loss: 0.0114 - mae: 0.0991 - val_loss: 0.0669 - val_mae: 0.3547 - learning_rate: 1.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0113 - mae: 0.0981 - val_loss: 0.0618 - val_mae: 0.3396 - learning_rate: 1.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 0.0134 - mae: 0.1041 - val_loss: 0.0661 - val_mae: 0.3519 - learning_rate: 1.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - loss: 0.0115 - mae: 0.0979 - val_loss: 0.0668 - val_mae: 0.3544 - learning_rate: 1.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m85/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0098 - mae: 0.0937\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0099 - mae: 0.0938 - val_loss: 0.0623 - val_mae: 0.3408 - learning_rate: 1.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0098 - mae: 0.0937 - val_loss: 0.0668 - val_mae: 0.3539 - learning_rate: 5.0000e-05\n",
            "Epoch 36/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - loss: 0.0115 - mae: 0.0979 - val_loss: 0.0634 - val_mae: 0.3441 - learning_rate: 5.0000e-05\n",
            "Epoch 37/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0119 - mae: 0.0982 - val_loss: 0.0652 - val_mae: 0.3494 - learning_rate: 5.0000e-05\n",
            "Epoch 38/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0112 - mae: 0.0969 - val_loss: 0.0613 - val_mae: 0.3377 - learning_rate: 5.0000e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0106 - mae: 0.0949 - val_loss: 0.0676 - val_mae: 0.3563 - learning_rate: 5.0000e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.0098 - mae: 0.0926 - val_loss: 0.0739 - val_mae: 0.3739 - learning_rate: 5.0000e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0116 - mae: 0.0974\n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0116 - mae: 0.0974 - val_loss: 0.0683 - val_mae: 0.3582 - learning_rate: 5.0000e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 0.0105 - mae: 0.0950 - val_loss: 0.0692 - val_mae: 0.3608 - learning_rate: 2.5000e-05\n",
            "Error: 'StockPredictor' object has no attribute 'plot_diagnostics'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HT4r-rOd9Ahz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}